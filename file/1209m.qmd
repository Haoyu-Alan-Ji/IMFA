---
title: 0129 meeting
author: Haoyu Ji
institute: Department of Biostatistics, University of Minnesota
csl: ../reflist2.csl
format:
  revealjs:
    theme: 
      - ../pre_style.scss
      - serif
    slide-number: true
    self-contained: true
---

# IMFA

::: {.justify}
## 1

Let $x_i=(x_{i1},\dots,x_{ip})^\top\in\mathbb{R}^p$，$i=1,\dots,N$

\begin{equation}\label{eq:imfa-mixture}
f(x_i\mid\Theta)=\sum_{g=1}^{\infty}\pi_g\ \mathcal N_p\!\big(x_i;\mu_g,\Sigma_g\big),
\qquad 
\Sigma_g=\Lambda_g\Lambda_g^\top+\Psi_g .
\end{equation}

For each cluster：
\begin{equation}\label{eq:fa-kernel}
x_i=\mu_g+\Lambda_g\eta_i+\varepsilon_{ig},\quad 
\eta_i\sim\mathcal N_q(0,I_q),\quad 
\varepsilon_{ig}\sim\mathcal N_p(0,\Psi_g),\quad 
\Psi_g=\mathrm{Diag}(\psi_{1g},\dots,\psi_{pg}).
\end{equation}
$\mu_g\in\mathbb{R}^p$ and $\Lambda_g\in\mathbb{R}^{p\times q}$ are mean and factor loading matrix，

$\Psi_g$ 为对角独特方差矩阵。

为便于推断，引入簇指示变量 $z_{ig}\in\{0,1\}$，满足 $\sum_{g\ge1} z_{ig}=1$，并可显式抽样因子得分 $\eta_i$。边缘化 $\eta_i$ 后，簇内协方差即为式 \eqref{eq:imfa-mixture} 中的 $\Sigma_g=\Lambda_g\Lambda_g^\top+\Psi_g$。
:::

::: {.justify}
## 2
How to generate a new cluster to make it infinite?

Use Pitman-Yor Procession (PYP),

\begin{equation}\label{eq:pyp-stick}
\nu_g\sim\mathrm{Beta}(1-d,\ \alpha+g d),\qquad 
\pi_g=\nu_g\prod_{\ell<g}(1-\nu_\ell),
\qquad d\in[0,1),\ \alpha>-d.
\end{equation}

When $d=0$ it's DP；$d>0$ 时具有更厚尾部，先验上更倾向产生更多小簇。

:::

::: {.justify}
## 3

In each cluster,

\begin{equation}\label{eq:mn-prior}
\Lambda_g^\top \sim \mathcal{MN}_{p\times q}\big(M_{0g}^\top,\ \Psi_g,\ B_{0g}\big).
\end{equation}

Thus, for $\psi_{jg}$：

\begin{equation}\label{eq:row-normal-prior}
\lambda_{jg}\mid \psi_{jg}\ \sim\ \mathcal N_q\big(m_{0,jg},\ \psi_{jg}B_{0g}\big),\qquad j=1,\dots,p,
\end{equation}

其中 $\lambda_{jg}$ 为 $\Lambda_g$ 的第 $j$ 行向量。矩阵正态的向量化协方差为
\begin{equation}\label{eq:cov-vec}
\operatorname{Cov}\!\big[\mathrm{vec}(\Lambda_g^\top)\big]=B_{0g}\otimes \Psi_g .
\end{equation}
这里 $B_{0g}\in\mathbb{R}^{q\times q}$ 控制列方向（因子维度方向）的先验协方差，$\Psi_g$ 控制行方向（观测变量方向）的尺度。
:::

::: {.justify}
## 4

Use slice sampling

对每个样本引入切片变量 $u_i>0$，并引入与 $\pi$ 独立的确定几何序列

\begin{equation}\label{eq:xi-geom}
\xi_g=(1-\rho)\rho^{g-1},\qquad \rho\in[0,1).
\end{equation}

Then,

\begin{equation}\label{eq:joint-x-u}
f(x,u\mid \Theta,\Pi)=\sum_{g=1}^{\infty} \pi_g\,\mathrm{Unif}\!\big(u;\ 0,\xi_g\big)\ \mathcal N_p\!\big(x;\ \mu_g,\Sigma_g\big).
\end{equation}

于是给定 $u_i$ 时，仅有有限多个分量满足 $u_i<\xi_g$，即“活跃簇集合”
\begin{equation}\label{eq:active-set}
A_\xi(u_i)=\{g:\ u_i<\xi_g\},\qquad 
\tilde G=\max_{1\le i\le N}\ |A_\xi(u_i)|.
\end{equation}
每次迭代只需对 $g\in\{1,\dots,\tilde G\}$ 的活跃簇进行计算与更新。经验上取 $\rho\approx0.75$ 常能兼顾混合与计算效率。

:::

::: {.justify}
## 5

给定活跃簇上界 $\tilde G$，IMFA 的联合密度（略去常数）可写为
\begin{equation}\label{eq:joint-density}
\begin{aligned}
&f(X,\{\eta_i\},Z,U,\Upsilon,\Theta)\ \propto\\
&\ \ \prod_{i=1}^N\prod_{g\in A_\xi(u_i)} \mathcal N_p\!\big(x_i;\ \mu_g+\Lambda_g\eta_i,\ \Psi_g\big)^{z_{ig}}
\ \cdot\ \prod_{i=1}^N \mathcal N_q(\eta_i;0,I_q) \\
&\ \ \cdot\ \prod_{i=1}^N\prod_{g\ge1} \Big(\tfrac{\pi_g}{\xi_g}\mathbf 1\{u_i<\xi_g\}\Big)^{z_{ig}}
\ \cdot\ \prod_{g\ge1} p(\nu_g\mid \alpha,d)\ \cdot\ \prod_{g\ge1} p(\mu_g,\Lambda_g,\Psi_g).
\end{aligned}
\end{equation}

\paragraph{更新 $\eta_i\mid z_i=g$（高斯--高斯）}
\begin{equation}\label{eq:eta-update}
V_{\eta,g}=\big(I_q+\Lambda_g^\top\Psi_g^{-1}\Lambda_g\big)^{-1},\quad 
m_{\eta,g}=V_{\eta,g}\Lambda_g^\top\Psi_g^{-1}\big(x_i-\mu_g\big),\quad
\eta_i\mid - \ \sim\ \mathcal N_q(m_{\eta,g},\ V_{\eta,g}).
\end{equation}

\paragraph{更新 $\Lambda_g$（矩阵正态，共轭块更新）}
将簇 $g$ 的样本堆成 $\tilde X_g=X_g-\mathbf 1\mu_g^\top$，$E_g=[\eta_i]_{i\in\mathcal I_g}$：
\begin{equation}\label{eq:Lambda-update}
B_{ng}^{-1}=B_{0g}^{-1}+E_g^\top E_g,\qquad 
M_{ng}^\top=\big(\tilde X_g^\top E_g + M_{0g}^\top B_{0g}^{-1}\big)\,B_{ng},
\end{equation}
\begin{equation}\label{eq:Lambda-post}
\Lambda_g^\top\mid -\ \sim\ \mathcal{MN}_{p\times q}\big(M_{ng}^\top,\ \Psi_g,\ B_{ng}\big).
\end{equation}

\paragraph{更新 $\mu_g$（高斯共轭）}
\begin{equation}\label{eq:mu-update}
V_{\mu,g}=\big(\phi I_p+N_g\Psi_g^{-1}\big)^{-1},\quad 
m_{\mu,g}=V_{\mu,g}\Big(\phi\,\tilde\mu + \Psi_g^{-1}\sum_{i\in\mathcal I_g}(x_i-\Lambda_g\eta_i)\Big),
\end{equation}
\begin{equation}\label{eq:mu-post}
\mu_g\mid - \ \sim\ \mathcal N_p(m_{\mu,g},\ V_{\mu,g}).
\end{equation}

\paragraph{更新 $\psi_{jg}$（逆伽马/伽马共轭）}
令残差 $r_{ijg}=x_{ij}-\mu_{jg}-\lambda_{jg}^\top\eta_i$：
\begin{equation}\label{eq:psi-update}
\psi_{jg}^{-1}\mid - \ \sim\ \mathrm{Ga}\Big(a_0+\tfrac{N_g}{2},\ b_{0j}+\tfrac12\sum_{i\in\mathcal I_g} r_{ijg}^2\Big).
\end{equation}

\paragraph{更新切片 $u_i$ 与分配 $z_i$}
\begin{equation}\label{eq:u-update}
u_i\mid z_i=g \ \sim\ \mathrm{Unif}(0,\xi_g),
\end{equation}
\begin{equation}\label{eq:z-update}
\mathbb P(z_i=g\mid -)\ \propto\ \frac{\pi_g}{\xi_g}\ \mathbf 1\{u_i<\xi_g\}\ 
\mathcal N_p\!\big(x_i;\ \mu_g+\Lambda_g\eta_i,\ \Psi_g\big),\quad g\in A_\xi(u_i).
\end{equation}

\paragraph{更新折棍 $\nu_g$ / 权重 $\pi_g$（PYP）}
记 $n_g=\sum_i z_{ig}$、$n_{>g}=\sum_{\ell>g} n_\ell$：
\begin{equation}\label{eq:nu-update}
\nu_g\mid -\ \sim\ \mathrm{Beta}\big(1-d+n_g,\ \alpha+g d+n_{>g}\big),\qquad 
\pi_g=\nu_g\prod_{\ell<g}(1-\nu_\ell).
\end{equation}
可进一步为 $(\alpha,d)$ 置超先验并用 MH 步更新（如 $\alpha$ 取 Gamma 超先验，$d$ 可在 $[0,1)$ 上设先验）。

:::

# Further Discussion

## Image processing

allow CI, legend......

## closure comparison

compare functions

number of risk: small to large, sample sequence and benchmarking methods(No paper did this)

## get censoring points

training NN, especially for plus sign(situations like different colors, same color, overlapping......)

CEN-KM cannot cover all the idea